{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain==0.1.16 langchain-community==0.0.34 langchain-openai==0.1.2 pinecone-client==3.0.0 python-dotenv==1.0.1 tiktoken==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq7hCySld3LI",
        "outputId": "a04f51f2-d3c2-4dac-c1a4-f52904fc4f0a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/199.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/199.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.9/199.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import pinecone\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_community.vectorstores import Pinecone as PineconeVectorStore"
      ],
      "metadata": {
        "id": "VoS1SX_-P5SA"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"PINECONE_API_KEY\"] = \"your_pinecone_api_key_here\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key_here\""
      ],
      "metadata": {
        "id": "sqiEpfIHfp1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc = pinecone.Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
        "index_name = \"yardstick-free-tier\""
      ],
      "metadata": {
        "id": "TmVWrmtrQdQ0"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=1536,\n",
        "        metric=\"cosine\",\n",
        "        spec=pinecone.ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "        )\n",
        "    )\n",
        "    print(f\"Created index '{index_name}'. Wait 1 minute...\")\n",
        "    time.sleep(60)\n",
        "else:\n",
        "    print(f\"Using existing index '{index_name}'\")\n",
        "\n",
        "\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDX6I_rYQeRL",
        "outputId": "9eefd428-7a03-4633-f0b2-a96135be0f6c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing index 'yardstick-free-tier'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader(\"https://web.archive.org/web/20231021031443/https://www.yardstickassessment.com/about\")\n",
        "documents = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "chunks = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "Gt1RqaVqVBPq"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SafeOpenAI:\n",
        "    def __init__(self):\n",
        "        self.last_call = 0\n",
        "        self.daily_usage = 0\n",
        "        self.RPM_LIMIT = 3\n",
        "        self.DAILY_LIMIT = 200\n",
        "\n",
        "    def embed(self, texts):\n",
        "        if self.daily_usage >= self.DAILY_LIMIT:\n",
        "            raise Exception(\"Daily limit reached\")\n",
        "\n",
        "\n",
        "        elapsed = time.time() - self.last_call\n",
        "        if elapsed < 60/self.RPM_LIMIT:\n",
        "            time.sleep(60/self.RPM_LIMIT - elapsed)\n",
        "\n",
        "        self.last_call = time.time()\n",
        "        self.daily_usage += 1\n",
        "        return OpenAIEmbeddings().embed_documents(texts)\n",
        "\n",
        "safe_openai = SafeOpenAI()"
      ],
      "metadata": {
        "id": "7R5pWF-UQhQQ"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader(\"https://web.archive.org/web/20231021031443/https://www.yardstickassessment.com/about\")\n",
        "documents = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "chunks = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "ut-bSItPQoHX"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    print(f\"Embedding {len(chunks)} chunks (Daily usage: {safe_openai.daily_usage}/{safe_openai.DAILY_LIMIT})\")\n",
        "\n",
        "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "    vector_db = PineconeVectorStore.from_documents(\n",
        "        documents=chunks,\n",
        "        embedding=embeddings,\n",
        "        index_name=index_name\n",
        "    )\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Pinecone failed: {str(e)}\")\n",
        "    print(\"Attempting local fallback...\")\n",
        "\n",
        "    try:\n",
        "        !pip install -q faiss-cpu\n",
        "\n",
        "        from langchain_community.vectorstores import FAISS\n",
        "        from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "        local_embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "        )\n",
        "\n",
        "        vector_db = FAISS.from_documents(\n",
        "            documents=chunks,\n",
        "            embedding=local_embeddings\n",
        "        )\n",
        "        print(\"Successfully created local FAISS vector store\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"FAISS failed: {str(e)}\")\n",
        "        print(\"Falling back to in-memory Chroma...\")\n",
        "\n",
        "        from langchain_community.vectorstores import Chroma\n",
        "        from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "        local_embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "        )\n",
        "\n",
        "        vector_db = Chroma.from_documents(\n",
        "            documents=chunks,\n",
        "            embedding=local_embeddings,\n",
        "            persist_directory=\"./chroma_db\"\n",
        "        )\n",
        "        print(\"Successfully created Chroma vector store\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_hPsBu3eWUz",
        "outputId": "48c1a90f-d3cd-4007-8fe0-d4d0fc6e467e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding 15 chunks (Daily usage: 3/200)\n",
            "Pinecone failed: module 'pinecone' has no attribute 'Index'\n",
            "Attempting local fallback...\n",
            "Successfully created local FAISS vector store\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0,\n",
        "    max_tokens=150\n",
        ")\n",
        "\n",
        "def ask_safely(question):\n",
        "    try:\n",
        "        if safe_openai.daily_usage >= safe_openai.DAILY_LIMIT:\n",
        "            return \"⚠️ Daily free limit reached (200 requests)\"\n",
        "\n",
        "\n",
        "        retriever = vector_db.as_retriever(search_kwargs={\"k\": 2})\n",
        "\n",
        "        qa_chain = RetrievalQA.from_chain_type(\n",
        "            llm=llm,\n",
        "            chain_type=\"stuff\",\n",
        "            retriever=retriever\n",
        "        )\n",
        "\n",
        "        elapsed = time.time() - safe_openai.last_call\n",
        "        if elapsed < 60/safe_openai.RPM_LIMIT:\n",
        "            time.sleep(60/safe_openai.RPM_LIMIT - elapsed)\n",
        "\n",
        "        safe_openai.daily_usage += 1\n",
        "        safe_openai.last_call = time.time()\n",
        "\n",
        "        result = qa_chain.invoke({\"query\": question})\n",
        "        return result.get(\"result\", \"No answer found\")\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)} (Usage: {safe_openai.daily_usage}/200 today)\""
      ],
      "metadata": {
        "id": "udDiOifoQwUO"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"What is computerized adaptive testing?\",\n",
        "    \"How does Yardstick ensure test validity?\",\n",
        "    \"What services does Yardstick offer?\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(f\"\\nQ: {q}\")\n",
        "    print(f\"A: {ask_safely(q)}\")\n",
        "    print(f\"Remaining today: {safe_openai.DAILY_LIMIT - safe_openai.daily_usage}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJLy-plTQ1d4",
        "outputId": "2937ff34-1aac-4a4e-8dc8-ff23f13539a8"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: What is computerized adaptive testing?\n",
            "A: Error: 'FieldInfo' object has no attribute 'items' (Usage: 4/200 today)\n",
            "Remaining today: 196\n",
            "\n",
            "Q: How does Yardstick ensure test validity?\n",
            "A: Error: 'FieldInfo' object has no attribute 'items' (Usage: 5/200 today)\n",
            "Remaining today: 195\n",
            "\n",
            "Q: What services does Yardstick offer?\n",
            "A: Error: 'FieldInfo' object has no attribute 'items' (Usage: 6/200 today)\n",
            "Remaining today: 194\n"
          ]
        }
      ]
    }
  ]
}